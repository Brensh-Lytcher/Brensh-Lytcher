日付 : 2024/06/17~21
Plan
  1. ニューラルネットワークモデルのパラメータの最適化
  2. ランダムフォレストモデルのパラメータの最適化
  3. コンペのデータと根源データの関連性について調べる
  4. 新しい特徴量の作成（探索）
  5. ディスカッションでヒントを探す

Do
  0. 準備
      先週の作業内容のうち、今回再利用するものを取り入れた。(型変換と作成した特徴量)
      ここで、先週のミスを発見した : 根源データがBank Customer Churn Predictionのデータであるが、Bank Customer Churnのデータを取り入れた。そのため、根源データoriginalについて再び調べた。originalのデータ数が10000, 欠損値が4つしかないので、そのまま削除した。また、trainとoriginalを結合したデータor_trも作った。

  1. ニューラルネットワークモデルのパラメータの最適化
      特徴量の一部のデータの範囲が広すぎるので、0~1の範囲にスケーリングした。(スケーリングしなければ、ニューラルネットワークモデルが動作できない、あるいは精度がかなり下がることが起きる。)スケーリングした後、予測精度が容易に0.87くらいに上がった。(スケーリングしない場合のスコアが0.78くらいしかない)
      隠れ層のサイズについて深く調べようとしたが、計算時間が長すぎたので、簡単なものに変えた。結果として、試したいくつかの隠れ層サイズのスコアがほとんど同じだった。
      活性化関数について、'logistic'のスコアが最も高かった。
      最適化手法について、準ニュートン法'lbfgs'は、max_iterが300以下のときにスコアが上がり、それ以上のときに下がる。最大スコアが0.880を超えた。勾配降下法'sgd'のスコアは30以上のときに下がる。(30以下はわからない。)最大スコアが0.8775前後であった。適応的モーメント推定'adam'のスコアが常に0.788くらいであり、max_iterを変えてもスコアが変化しない。したがって、準ニュートン法かつmax_iter=300~400が最適である。
      
  2. ランダムフォレストモデルのパラメータの最適化
      n_estimators: 4000
      max_features: 2
      max_depth: 15前後
      min_samples_leaf: 0.0002
      ランダムフォレストモデルのスコアが最大でも0.88くらいしかない。

  3. コンペのデータと根源データの関連性について調べる
      originalデータを使った場合の予測精度が使わない場合より0.004くらい低くなるので、これ以降はoriginalを使わない。

  4. 新しい特徴量の作成（探索）
      CustomerIdの現れる回数と口座解除率が予測に役立ったので、Surnameについても同様に調べた。その結果、Surnameが現れる回数が予測精度を0.002くらい上げ、各Surnameの口座解除率が予測精度を0,006くらい上げた。
      ここで、ある問題点を発見した。作った特徴量が予測に役立つかを判定する方法は、訓練用データの一部を検証データとして予測精度を調べているので、役立つものと判定されても、testデータの予測に役立たない可能性がある。たとえば、CustomerIdの口座解除率は訓練データのCustomerIdごとのExited=1の割合であるため、これが検証データ（訓練データの一部）の予測に役立つのは当然のことであるが、testの予測に役立つとは限らない。なので、作成した特徴量の有効性の検証はtestデータで行うべきだ。
      ほかに考えられる特徴量作成方法として、Multi-Class Prediction of Obesity Riskで多項式特徴量と主成分分析が学習したので、それを使ってみようと思ったが、ディスカッションでA feature engineering effort that is worth nothing[1]というコードを見つかって、それはoriginal, Polynomial features(多項式特徴量), PCA(主成分分析)とcluster analysis(クラスタ分析)すべてが無効であることを示したので、それらの特徴量の作成をあきらめた。

  5. ディスカッションでヒントを探す
      上述のように、新たな特徴量の作成はあまり役に立たない、というコメントがたくさん見つかった。また、上位解法の多くはCatBoostClassifierを使っていたので、来週はそのモデルについて調べるつもりだ。

  6. testデータの予測結果の提出
      4.新しい特徴量の作成で述べたように、作成した特徴量の有効性を判断するために、testデータの予測結果のスコアを調べることが必要であるので、Submissionを提出した。
      検証データの予測精度が0.88前後に達したにもかかわらず、SubmissionのPublic ScoreとPrivate Scoreが0.73前後しかなかった。よく確認したら、正式のスコア判定方法は正しく判定されたものの割合ではなく、ROCカーブが使われる。現在の自分の順位が下位10%にあり、ゴール(上位10%に入るいこと)達成の自信を失った。
      test score(Public ScoreとPrivate Scoreはこれ以降test scoreという)より、作成した4つの特徴量がすべて無効な特徴量だということが判明された。

Check
  1. ニューラルネットワークモデルとランダムフォレストモデルのパラメータについて調べて、適切なカテゴリ（値）を見つけた。ただし、実行時間を考慮した上で、パラメータの求め方を簡略化したので、厳密な最適パラメータになっていない。
  2. 根源データの有効性について調べた結果、それが全く役立たないことがわかった。
  3. 新しい特徴量について、CustomerIdとSurnameそれぞれの現れる回数と各カテゴリの口座解除率が検証データの予測精度を上げたが、testデータの予測において有効かどうかがわからない。また、多項式特徴量や主成分分析などによって作り出す特徴量がすべて役に立たないものだ、というコメントがたくさんあるので、それらをあきらめた。
  4. ディスカッションで、CatBoostClassifierが最も有効なモデルだという意見がたくさんあることを発見した。

Action
  1. 自分が前半の授業で学習した機械学習手法は予測精度の向上に少し役に立ったが、まだ不十分だ。この後はCatBoostClassifierについて学習すべきだ。
  2. 訓練データの一部でモデルを検証することは便利だけど、コンペのスコア計算法が正しく予測できたデータの割合ではないので、testデータの予測結果を提出して、test scoreを見た方がよいだ。
  3. 課題のゴールが高すぎるので、この後はCatBoostClassifierのスコアをもとにゴールを調整した方がよい。

参考文献
  [1] Riza Temizel: A feature engineering effort that is worth nothing, https://www.kaggle.com/code/rzatemizel/a-feature-engineering-effort-that-is-worth-nothing/comments
