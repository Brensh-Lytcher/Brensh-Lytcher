日付 : 2024/07/16~19
Plan
  1. 回帰モデルと分類モデルのスコアの違いの調査
  2. 前回作成した特徴量を使って、パラメータを簡単に調整してスコアの分布を確認する
  3. 埋め込み法で重要な特徴量を抽出して、再予測する

Do
  1. 回帰モデルと分類モデルのスコアの違いの調査
      コンペが与えた基本的な特徴量だけを使って(つまり自作特徴量を使わない)、パラメータを調整せずに予測した結果、CatBoostClassifierのスコアが0.75154であったのに対して、CatBoostRegressorのスコアが0.88697もあった。前者が上位80%から90%の間にあるが、後者が上位50%から60%の間にある。よって、このコンペにおいて、回帰モデルが分類モデルよりはるかに良いことがわかる。しかし、このコンペは口座を解除するかどうかを予測する、つまり2クラス分類であるべきなのに、なぜ回帰分析の結果である0から1の間の連続値が予測結果として使える、しかもスコアが分類モデルよりはるかに高いのか、という疑問を抱えた。そのため、私はコンペのスコア計算方法(ROC曲線の下の面積)について調べた。
      ROC曲線は、予測対象の予測確率を閾値に基づいて真偽に分類するとき、縦軸をTPR（真陽性率）、横軸をFPR（偽陽性率）として、予測確率の分類閾値を変化しながらグラフに点をプロットして得られる曲線である。ROC曲線の下側の面積をAUC(Area Under the Curve)という。予測確率のランダム性が強いほど、ROC曲線が点(0,0)と(1,1)を繋ぐ線分に近づき、AUCが0.5に近づく。逆に、予測が正しいほど、ROC曲線が点(0,0)と(0,1)を結ぶ線分および点(0,1)と(1,1)を結ぶ線分からなる直角カーブに近づき、AUCが1に近づく。[1]
      したがって、このコンペの提出データは予測結果ではなく、予測確率であるべきだ。そのため、


Check


Action


参考文献
  [1] キカガクブログ:「【評価指標】ROC 曲線と AUC についてわかりやすく解説してみた」，キカガク。更新日(2024年4月15日), アクセス日(2024年7月16日)。https://www.kikagaku.co.jp/kikagaku-blog/roc-auc/
