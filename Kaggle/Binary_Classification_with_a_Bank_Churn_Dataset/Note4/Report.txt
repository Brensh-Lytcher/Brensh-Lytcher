日付 : 2024/07/01~05
Plan
  1. アンサンブル学習を使って予測する
  2. 役に立ちそうな特徴量について考えて、思いついたら実際に使ってみる

Do
  1. アンサンブル学習を使って予測する
      ランダムフォレスト、K-近傍法、ロジスティック回帰、ニューラルネットワークと勾配ブースティング分類器(CatBoostClassifier)の5つのモデルとバギング、スタッキングの2つのアンサンブル学習手法を使って予測する。
      アンサンブル学習の準備として、5つのモデルのパラメータ最適化を行った。ただし、trainデータの一部を検証データとして最適化したのではなく、testデータを予測して予測結果を提出し、test scoreを確認することで最適化パラメータを調べた。このようにすることで、モデルの評価がより正しくなる。しかし、1日に提出できる予測結果の数が限られていて、パラメータの調整を一々自分で調整しなければならないので、作業量が大きく、調べられるパラメータ数が少なく、厳密な最適パラメータが得られなかった。
      バギングについて、使用するモデルの指定、各モデルの重みの指定、訓練データの割合の指定、予測確率の使用の指定などができるような関数を作成した。スタッキングについて、学習モデルの指定、統合モデルの指定、訓練データの割合の指定、予測確率の使用の指定などができるような関数を作成した。それぞれの手法についても、パラメータを調整しながらtest scoreを調べて、最適パラメータを調べた。しかし、スコアがそれほど上がっていなかった。また、予測確率の情報量が予測結果より多いけど、予測確率を使わない場合のスコアが使う場合より高くなることが多かった。なぜこのようになったのかはわからないが、考えられる仮説は、複数のモデルが0.5前後の低い確率で正しく予測し、あるモデルが0または1前後の高い確率で間違って予測するとき、予測確率を使わなければ、多数決で正しい結果が得られるが、予測確率を使ったら、極端に大きい値あるいは極端に小さい値に影響されて、間違った結果が得られる。(平均値が外れ値に大きく影響されることと同様)

  2. 役に立ちそうな特徴量について考えて、思いついたら実際に使ってみる
      すべての特徴量の間に関係が考えられないので、各特徴量からなる多項式は役に立たないと考えられる(この前でも同じことを他人のコードから確かめた)。また、離散型特徴量に基づいていくつかの部分に分けて、それぞれの部分の口座解除率(目的変数が1の割合)を特徴量とすることは、ランダムフォレストと一致するので、このような特徴量が予測に役立たないと考えられる。したがって、仮に有効な特徴量が存在すれば、それはおそらく根源データにある可能性が高いと考えられる。しかし、この前に試したように、根源データを直接訓練データとすると、スコアが逆に下がってしまったので、根源データと訓練データの間の関係を調べて、特徴量を作成することしかできない。よって、以下の方法を考えた。
      (1)離散型データの組み合わせについて、根源データに含まれるな訓練データと含まれない訓練データに分けて、それぞれの口座解除率、あるいは口座解除の近似性について調べる。
      (2)共通の口座番号を持つ訓練データが根源データにどれくらい類似しているかについて調べる。
      (3)「貯金の有無」という特徴量を作成して、(1)と同様に調べる。

Check
  1. アンサンブル学習について、パラメータ最適化した5つのモデルをバギングとスタッキングの2つの手法それぞれで統合して予測した。しかし、test scoreが最大でも0.775くらいしかなかった。
  2. 新しい特徴量について、その可能な作成方法を考えたが、アンサンブル学習に大量の時間をかかったため、特徴量を実際に作成していなかった。

Action
  1. アンサンブル学習が予想ほど大きな役割を果たしていなかったので、test scoreを0.88に上げるためには、アンサンブル学習だけではできない。
  2. 今後はまず新しい特徴量を作成して検証する。その後、他人のコード・意見からスコア向上法を調べる。
