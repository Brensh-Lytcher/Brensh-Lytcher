日付 : 2024/05/14
Plan
  1. 4月18日に調べてまとめた4つの高スコアコードを理解して、実践する。

Do
  1. コード1    [1]
      コード1はデータの前処理を示している。以下はその前処理の手法である。
      (1) pandas.cut()    [3]
          データを与えられた境界値で分割、あるいはn等分する。
          考察: データをいくつかの階級に分けることで、未成年者と成年者、あるいは高齢者などを分類することが可能である。
      (2) numpy.log1p()    [4]
          データの対数をとる。log1pはlog10、log2pはlog100...
          考察: データの歪度が高い場合、それを正規分布に近似したものに変換できる。データ分布密度が高い範囲における分類を容易にすることができるだろう。numpy.pow()でデータのべき乗を作ることにも同じ役割があると考えられる。
      (3) sklearn.preprocessing.MinMaxScaler()    [5]
          説明変数のデータXを下の式によってminとmaxの間の数に変換する。
            X_new = ((X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))) * (max - min) + min
          parameters:
            -feature_range:tuple (min, max), default=(0, 1)
              変換したデータの範囲を指定する(X_newの式の中のminとmax)
            -copy:bool, default=True
              変換してできたデータを新しい特徴量にするか。(Falseだと、元のデータが削除され、新しいデータが代入される)
            -clip:bool, default=False
              不明
          考察: データを指定範囲に収めることで、統計的性質を近似するもの調節して、機械学習の精度が高められる。MinMaxScalar()の他に、以下の手法もある。    [6]
              スケーリング:
                -sklearn.preprocessing.MaxAbsScaler()    [7]
                  データを-1~1の範囲内に収める。計算式はXi_new = Xi / max{abs(X)}
                -sklearn.preprocessing.RobustScaler()    [8]
                  データの中央値を0に、第1四分位数と第3四分位数の距離を1にスケーリングする。外れ値を持つデータに強いことが特徴。
              標準化:
                -sklearn.preprocessing.StandardScaler()    [9]
                  データの平均値を0に、標準偏差を1に標準化する
              非線形変換:
                -sklearn.preprocessing.PowerTransformer()    [10]
                  method = 'box-cox'の場合:
                    Box-Cox変換を使って、正数からなるデータの歪度を小さくする。Box-Cox変換の式は以下の式である。
                          (x^λ - 1) / λ      (λ > 0)
                    x = { ln(x)             (λ = 0)
                  method = 'yeo-johnson'の場合:
                    Yeo-Johnson変換を使って、実数からなるデータの歪度を小さくする。Yeo-Johnson変換の式は以下の式である。
                          ((x + 1)^λ - 1) / λ                      (λ != 0, x >= 0)
                    x = { ln(x + 1)                                (λ = 0, x >= 0)
                          -((-x + 1)^(2 - λ) - 1) / (2 - λ)        (λ != 2, x < 0)
                          -ln(-x + 1)                              (λ = 2, x < 0)
      (4) sklearn.preprocessing.LabelEncoder()    [11]
          目的変数の文字列データ(カテゴリ)を整数に変換する。
          考察: 名義尺度のデータの数値化には役立つが、順序尺度のデータの数値化には不適切だ。現在のコンペの目的変数は適正体重であり、順序尺度のデータであるため、このコードのやり方がよくないと思う。順序尺度のデータの数値化はsklearn.preprocessing.OrdinalEncoder()を使うべきだ。そのパラメータcatogoryを指定することで、カテゴリの順番を指定できる。
      (5) BMI
          コード1は適正体重BMIを使っている。これは自分のやり方と同じである。
      (6) Age * Gender
          コードはAge * Genderの説明変数を作成するが、説明変数Genderがオブジェクト型のデータなので、掛け算ができない。
          考察: 年齢×性別はどんが意義があるかがよくわからないが、性別を数値に変換しなければならないので、Age*Genderが意味を持つように性別に適当な数値を与えるべきだ。そこで、性別に-1と1を割り当てる方法が考えられる。つまり、年齢に正負の符号をつけることで、男女を区別できる。この方法によって、モデルを学習させるときに、同じ年齢のデータに対して男女が混合されない。
      (7) pandas.get_dummies()
          カテゴリのデータを文字列ごとにboolean型説明変数に変える。たとえば、'A'という説明変数に'abc'と'ABC'の2種類のデータがある場合、それをダミー変数に変えると、'A'の説明変数が削除されて、'A_abc'と'A_ABC'の2種類の説明変数が作成され、'A'の'abc'データに対応する'A_abc'と'A_ABC'のデータがそれぞれ'True'と'False'であり、'A'の'ABC'データに対応する'A_abc'と'A_ABC'のデータがそれぞれ'False'と'True'である。
          考察: get_dummies()はカテゴリデータの変換が容易にできる。しかし、 Multi-Class Prediction of Obesity Riskのデータには'yes'と'no'の2種類のデータからなる説明変数があり、それをダミー変数に変換すると..._yesと..._noの2つの説明変数が作られるが、'yes'と'no'を直接TrueとFalseに変換することが望ましいので、get_dummiesを使うのは不適切だ。
      (8) sklearn.preprocessing.PolynomialFeatures()    [12]
          パラメータdegreeの値をnとする。このとき、PolynomialFeatures.fit_transform(data[feature1, feature2, ..., featurek])はfeature1, feature2, ..., featurekのk個の特徴量からn次以下の項をすべて作り出す。
          考察: data[a, b]の2次以下の項は1, a, b, a^2, a*b, b^2であるが、コード1では生成した特徴量の名称が間違っていたので、それを修正した。この関数は新たな特徴量の生成の便利であるが、a+tbやta/bなどのような式が作れないという欠点があるので、特徴量の作成において、PolynomialFeaturesに頼りすぎないように注意すべきだ。

  2. コード2



Check


Action


参考文献
  [1] Kirderf: 4th place solution: Stacking with XGB + Pseudo labeling + metric optimizing., https://www.kaggle.com/competitions/playground-series-s4e2/discussion/480939
  [2] Divyam6969: (Best Solution😏) Multiclass Obesity🫄Prediction, https://www.kaggle.com/code/divyam6969/best-solution-multiclass-obesity-prediction
  [3] note.nkmk.me: pandasのcut, qcut関数でビニング処理（ビン分割）, https://note.nkmk.me/python-pandas-cut-qcut-binning/
  [4] note: 機械学習のための対数変換 - NumPyのlog1p関数, https://note.com/sasayaka360/n/n5d166a796d66
  [5] scikit-learn: sklearn.preprocessing.MinMaxScaler, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html
  [6] PYTHON for PROGRAMMERS: 【Python】scikit-learnによる正規化/標準化/スケーリングの実装方法, https://note-tech.com/python_scaling_standardize/#toc6
  [7] scikit-learn: sklearn.preprocessing.MaxAbsScaler, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html
  [8] scikit-learn: sklearn.preprocessing.RobustScaler, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html
  [9] scikit-learn: sklearn.preprocessing.StandardScaler, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html
  [10] scikit-learn: sklearn.preprocessing.PowerTransformer, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html
  [11] scikit-learn: sklearn.preprocessing.LabelEncoder, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html
  [12] scikit-learn: sklearn.preprocessing.PolynomialFeatures, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html
