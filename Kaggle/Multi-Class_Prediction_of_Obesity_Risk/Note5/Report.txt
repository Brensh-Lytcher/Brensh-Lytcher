æ—¥ä»˜ : 2024/04/18
Plan
  1. 4æœˆ18æ—¥ã«èª¿ã¹ã¦ã¾ã¨ã‚ãŸ4ã¤ã®é«˜ã‚¹ã‚³ã‚¢ã‚³ãƒ¼ãƒ‰ã®æ‰“ã¡ã®2ã¤ã‚’ç†è§£ã—ã¦ã€å®Ÿè·µã™ã‚‹ã€‚

Do
  1. ã‚³ãƒ¼ãƒ‰1    [1]
      ã‚³ãƒ¼ãƒ‰1ã¯ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ä»¥ä¸‹ã¯ãã®å‰å‡¦ç†ã®æ‰‹æ³•ã§ã‚ã‚‹ã€‚
      (1) pandas.cut()    [3]
          ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Žãˆã‚‰ã‚ŒãŸå¢ƒç•Œå€¤ã§åˆ†å‰²ã€ã‚ã‚‹ã„ã¯nç­‰åˆ†ã™ã‚‹ã€‚
          è€ƒå¯Ÿ: ãƒ‡ãƒ¼ã‚¿ã‚’ã„ãã¤ã‹ã®éšŽç´šã«åˆ†ã‘ã‚‹ã“ã¨ã§ã€æœªæˆå¹´è€…ã¨æˆå¹´è€…ã€ã‚ã‚‹ã„ã¯é«˜é½¢è€…ãªã©ã‚’åˆ†é¡žã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ã€‚
      (2) numpy.log1p()    [4]
          ãƒ‡ãƒ¼ã‚¿ã®å¯¾æ•°ã‚’ã¨ã‚‹ã€‚log1pã¯log10ã€log2pã¯log100...
          è€ƒå¯Ÿ: ãƒ‡ãƒ¼ã‚¿ã®æ­ªåº¦ãŒé«˜ã„å ´åˆã€ãã‚Œã‚’æ­£è¦åˆ†å¸ƒã«è¿‘ä¼¼ã—ãŸã‚‚ã®ã«å¤‰æ›ã§ãã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒå¯†åº¦ãŒé«˜ã„ç¯„å›²ã«ãŠã‘ã‚‹åˆ†é¡žã‚’å®¹æ˜“ã«ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã ã‚ã†ã€‚numpy.pow()ã§ãƒ‡ãƒ¼ã‚¿ã®ã¹ãä¹—ã‚’ä½œã‚‹ã“ã¨ã«ã‚‚åŒã˜å½¹å‰²ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚
      (3) sklearn.preprocessing.MinMaxScaler()    [5]
          èª¬æ˜Žå¤‰æ•°ã®ãƒ‡ãƒ¼ã‚¿Xã‚’ä¸‹ã®å¼ã«ã‚ˆã£ã¦minã¨maxã®é–“ã®æ•°ã«å¤‰æ›ã™ã‚‹ã€‚
            X_new = ((X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))) * (max - min) + min
          parameters:
            -feature_range:tuple (min, max), default=(0, 1)
              å¤‰æ›ã—ãŸãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’æŒ‡å®šã™ã‚‹(X_newã®å¼ã®ä¸­ã®minã¨max)
            -copy:bool, default=True
              å¤‰æ›ã—ã¦ã§ããŸãƒ‡ãƒ¼ã‚¿ã‚’æ–°ã—ã„ç‰¹å¾´é‡ã«ã™ã‚‹ã‹ã€‚(Falseã ã¨ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒä»£å…¥ã•ã‚Œã‚‹)
            -clip:bool, default=False
              ä¸æ˜Ž
          è€ƒå¯Ÿ: ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šç¯„å›²ã«åŽã‚ã‚‹ã“ã¨ã§ã€çµ±è¨ˆçš„æ€§è³ªã‚’è¿‘ä¼¼ã™ã‚‹ã‚‚ã®èª¿ç¯€ã—ã¦ã€æ©Ÿæ¢°å­¦ç¿’ã®ç²¾åº¦ãŒé«˜ã‚ã‚‰ã‚Œã‚‹ã€‚MinMaxScalar()ã®ä»–ã«ã€ä»¥ä¸‹ã®æ‰‹æ³•ã‚‚ã‚ã‚‹ã€‚    [6]
              ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°:
                -sklearn.preprocessing.MaxAbsScaler()    [7]
                  ãƒ‡ãƒ¼ã‚¿ã‚’-1~1ã®ç¯„å›²å†…ã«åŽã‚ã‚‹ã€‚è¨ˆç®—å¼ã¯Xi_new = Xi / max{abs(X)}
                -sklearn.preprocessing.RobustScaler()    [8]
                  ãƒ‡ãƒ¼ã‚¿ã®ä¸­å¤®å€¤ã‚’0ã«ã€ç¬¬1å››åˆ†ä½æ•°ã¨ç¬¬3å››åˆ†ä½æ•°ã®è·é›¢ã‚’1ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã€‚å¤–ã‚Œå€¤ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã«å¼·ã„ã“ã¨ãŒç‰¹å¾´ã€‚
              æ¨™æº–åŒ–:
                -sklearn.preprocessing.StandardScaler()    [9]
                  ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã‚’0ã«ã€æ¨™æº–åå·®ã‚’1ã«æ¨™æº–åŒ–ã™ã‚‹
              éžç·šå½¢å¤‰æ›:
                -sklearn.preprocessing.PowerTransformer()    [10]
                  method = 'box-cox'ã®å ´åˆ:
                    Box-Coxå¤‰æ›ã‚’ä½¿ã£ã¦ã€æ­£æ•°ã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã®æ­ªåº¦ã‚’å°ã•ãã™ã‚‹ã€‚Box-Coxå¤‰æ›ã®å¼ã¯ä»¥ä¸‹ã®å¼ã§ã‚ã‚‹ã€‚
                          (x^Î» - 1) / Î»      (Î» > 0)
                    x = { ln(x)             (Î» = 0)
                  method = 'yeo-johnson'ã®å ´åˆ:
                    Yeo-Johnsonå¤‰æ›ã‚’ä½¿ã£ã¦ã€å®Ÿæ•°ã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã®æ­ªåº¦ã‚’å°ã•ãã™ã‚‹ã€‚Yeo-Johnsonå¤‰æ›ã®å¼ã¯ä»¥ä¸‹ã®å¼ã§ã‚ã‚‹ã€‚
                          ((x + 1)^Î» - 1) / Î»                      (Î» != 0, x >= 0)
                    x = { ln(x + 1)                                (Î» = 0, x >= 0)
                          -((-x + 1)^(2 - Î») - 1) / (2 - Î»)        (Î» != 2, x < 0)
                          -ln(-x + 1)                              (Î» = 2, x < 0)
                    
      (4)
      ã“ã‚Œã¯ãƒ‡ãƒ¼ã‚¿ã®


Check


Action


å‚è€ƒæ–‡çŒ®
  [1] Kirderf: 4th place solution: Stacking with XGB + Pseudo labeling + metric optimizing., https://www.kaggle.com/competitions/playground-series-s4e2/discussion/480939
  [2] Divyam6969: (Best SolutionðŸ˜) Multiclass ObesityðŸ«„Prediction, https://www.kaggle.com/code/divyam6969/best-solution-multiclass-obesity-prediction
  [3] note.nkmk.me: pandasã®cut, qcuté–¢æ•°ã§ãƒ“ãƒ‹ãƒ³ã‚°å‡¦ç†ï¼ˆãƒ“ãƒ³åˆ†å‰²ï¼‰, https://note.nkmk.me/python-pandas-cut-qcut-binning/
  [4] note: æ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®å¯¾æ•°å¤‰æ› - NumPyã®log1pé–¢æ•°, https://note.com/sasayaka360/n/n5d166a796d66
  [5] scikit-learn: sklearn.preprocessing.MinMaxScaler, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html
  [6] PYTHON for PROGRAMMERS: ã€Pythonã€‘scikit-learnã«ã‚ˆã‚‹æ­£è¦åŒ–/æ¨™æº–åŒ–/ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®å®Ÿè£…æ–¹æ³•, https://note-tech.com/python_scaling_standardize/#toc6
  [7] scikit-learn: sklearn.preprocessing.MaxAbsScaler, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html
  [8] scikit-learn: sklearn.preprocessing.RobustScaler, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html
  [9] scikit-learn: sklearn.preprocessing.StandardScaler, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html
  [10] scikit-learn: sklearn.preprocessing.PowerTransformer, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html


  [4] scikit-learn: sklearn.preprocessing.LabelEncoder, https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html
