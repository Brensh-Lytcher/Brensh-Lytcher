日付 : 2024/04/18
Plan
  1. 「Multi-Class Prediction of Obesity Risk」のデータを整理し、各データの意味を理解する
  2. 各データの予測における重要度を調べる方法を学び、実践する
  3. 各データの間の関連性、組み合わせることの可能性を調べる
  4. 主な機械学習のモデルの一覧を作る
  5. スコアの高いコードを調べて、代表的なものをまとめる
  6. ディスカッションを見て、有用なもののキーワードをまとめる

Do
  1. id以外のデータの型はobjectとfloat64の2種類のみであり、データに欠損がない。データは主に個人情報（健康に関係がある）、食習慣情報、（非食事）生活習慣情報の3種類に分類できる。object型データをその順序尺度に応じて整数値データに変えた。予測したいデータはどれくらい肥満であるかの評価であり、BMIの肥満判定基準に対応付けられる。
  2. データの特徴量選択法（有効なデータを見つける方法）として、基本的にフィルタ法、ラッパー法、埋め込み法の3つがある。[1]
     フィルタ法: 説明変数（特徴量）と目的変数の相関係数（ほかの係数でもよい）を求め、その絶対値が基準以上のものを候補とする。候補説明変数同士の相関係数の絶対値がある基準以上であるものがあれば、そのうちの1つのみを残し、他の物を排除する。残ったものがすべて有効な特徴量となる。
    (思考:A,Bの2つの説明変数それぞれと目的変数の間の相関が低いが、AとBを組み合わせたものと目的変数の相関が高い場合が考えられる。このような特徴量は木構造モデルに使えると考えられる。また、説明変数と目的変数の散布図が2次関数、3次関数などの曲線に近い場合、相関係数が0に近い可能性がある。フィルタ法はこのようなデータを抽出できないだろう。)
     ラッパー法: すべての特徴量でモデルを構築して、予測を行う。次に、どれか1つの特徴量を除いて構築したモデルの予測精度の増加量が基準値以上であれば、その特徴量がノイズであることがわかる。その特徴量を除いた後、さらにどれか1つの特徴量を除いて構築したモデルの予測精度の増加量を調べる。このようにずっと繰り返して、すべてのノイズを除去する。
     (思考:使用するモデルによって特徴量の重要度が決まることがある。また、モデルを構築するときのデータの順番によって特徴量の重要度が決まることがある。よって、複数個のモデルを使って、それぞれにデータの順番を変えながら複数回予測する必要がある。したがって、この方法の計算量がかなり大きい。また、予測精度増加量の基準値をどう決めればよいかも問題になる。)
     埋め込み法: 構築するモデルそのものに特徴量選択のメカニズムが入っていて、予測に必要な特徴量の係数が大きくなり、予測に必要のない特徴量の係数が0に近づく。
     (思考: ニューラルネットワーク構造や進化論的計算法などのようなものが考えられる。このようなモデルの計算時間がほかのモデルより長いらしい)
     フィルタ法（基準値を0.3とおいて、相関係数の絶対値が0.3以下であれば無相関とみなす）で選んだ特徴量はWeight, CAEC, Ageの3つであった。ラッパー法と埋め込み法はモデルを使うので、今度はそれをやめた。モデルの学習が終わった後にもう一度特徴量選択を行う予定にする。
  3. 

Check


Action

参考文献
[1] セールスアナリティクス：基本となる3つの特徴選択手法とPythonでの実装，https://www.salesanalytics.co.jp/datascience/datascience145/#Embedded_Method
[2]
