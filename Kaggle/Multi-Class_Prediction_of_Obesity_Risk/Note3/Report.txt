2024/05/01~03
Plan
  1. モデルの可視化方法を調べる
  2. 決定木(Decision Trees)モデルの学習と実践
  3. ランダムフォレスト(Random Forest)モデルの学習と実践
  4. ニューラルネットワーク(Neural Networks)モデルの学習と実践

Do
  1. モデルの可視化
      -決定境界の可視化
        func: mlxtend.plotting.plot_decision_regions()
        parameters:
          -X:array-like, shape=[n_samples, n_features]
            説明変数(numpy.ndarray)
          -y:array-like, shape=[n_samples]
            目的変数(numpy.ndarray)
          -clf:Classifer object
            分類モデル
          -feature_index:array-like(default:(0,) for 1D, (0,1) otherwise)
            x,y軸の特徴量
          -filler_feature_values:dict(default:None)
            特徴量(説明変数)が3つ以上の場合, 未使用の特徴量の値を指定
          -filler_feature_ranges
            filler_feature_valuesで指定した値からのずれの範囲を指定
          -ax:matplotlib.axes.Axes(default:None)
            matplotlibのaxと同様
          -X_highlight:array-like, shape=[n_samples, n_features](default:None)
            ハイライト表示するデータを指定
          -zoom_factor:float(default:1.0)
            不明
          -hide_spines:bool(default:True)
            軸の表示
          -legend:int(default:1)
            凡例の位置
          -markers:str(default:'s^oxv<>')
            データの記号
          -colors:str(default:'red,blue,limegreen,gray,cyan')
            色の指定
          -scatter_kwargs:dict(default:None)
            不明。matplotlibのscatterと関係があるもの
          -contourf_kwargs:dict(default:None)
            不明。matplotlibのcontourfと関係があるもの
          -contour_kwargs:dict(default:None)
            不明。matplotlibのcontourと関係があるもの
          -scatter_highlight_kwargs:dict(default:None)
            不明。matplotlibのscatterと関係があるもの
          -n_jobs:int or None, optional(default=None)
            計算に使用するCPUの数

        func: seaborn_analyzer.classplot.class_separator_plot()
        parameters:
          -clf(classifier object implementing)
            モデル
          -x:List[str], or np.ndarray
            説明変数
          -y:str or np.ndarray
            目的変数
          -data:pd.DataFrame
            入力データ
          -x_colnames:List[str], default=None
            dataがpd.DataFrameでない場合に入力データのラベルリストを指定する
          -x_chart:List[str], default=None
            説明変数の内のグラフ表示対象
          -pair_sigmarange:float, default=1.0
            グラフ表示しない説明変数の分割範囲
          -pair_sigmainterval:float, default=0.5
            グラフ表示しない説明変数の1枚当たりの表示範囲
          -chart_extendsigma:float, default=0.5
            グラフx,y軸の表示拡張範囲
          -char_scale:int, default=1
            グラフ解像度倍率(大きいほど描画速度が速くなるが、画像が粗くなる)
          -plot_scatter=:{'error', 'class', 'class_error', None}, default='class_error'
            散布図の描画種類。errorは分類正誤、classはクラスを色表示、class_errorは各クラスの分類正誤の色表示
          -rounddigit_x3:int, default=2
            グラフ表示しない変数の小数丸め桁数
          -scatter_colors:List[str], default=None
            各クラスのデータの色(plot_scatterがclassまたはclass_errorのときのみに使える)
          -true_marker:str, default='o'
            正しく分類されたデータのマーク
          -false_marker:str, default='x'
            誤分類されたデータのマーク
          -cv:int, cross-validation generator, or an iterable, default=None
            クロスバリデーション分割法を決める。Noneの場合は5-fold cross validation, intの場合はKFoldを使用。
          -cv_seed:int, default=42
            cross validationの乱数シード
          -cv_group:str, default=None
            グループ分割における対象カラム名
          -display_cv_indices:int, default=0
            クロスバリデーション分割の番号
          -clf_params:dict, default=None
            モデルに渡すパラメータ
          -fit_params:dict, default=None
            モデル学習時のパラメータ
          -eval_set_selection:{'all', 'test', 'train', 'original', 'original_transformed'}, default=None
            モデル学習に使うデータを指定
          -subplot_kws:dict, default=None
            matplotlib.pyplot.subplotsに渡す引数
          -contourf_kws:dict, default=None
            matplotlib.pyplot.contourf(描画用)に渡す引数
          -scatter_kws:dict, default=None
            matplotlib.pyplot.scatterに渡す引数
          -legend_kws:dict, default=None
            凡例指定
            
        mlxtend.plotting.plot_decision_regions()はndarray型のデータしか扱えないので、前処理が必要。それに対して、seaborn_analyzer.classplot.class_proba_plot()は前処理の必要がないので、使いやすい

      -クラス確率の可視化
        func: seaborn_analyzer.classplot.class_proba_plot()
        parameters:
          seaborn_analyzer.classplot.class_separator_plot()のparameterをすべて持つ。そのほかのparameterは以下の通りである。
          -plot_border:bool, default=True
            分類の境界線の表示
          -proba_class:str, List[str], default=None
            確率表示となる対象のクラス名(指定クラスの確率のみを表示する)
          -proba_cmap_dict:dict[str,str], default=None
            各クラスの確率図の色(データの色ではなく,範囲の背景色)指定
          -proba_type:{'contourf', 'contour', 'imshow'}, default='contourf'
            確率図の種類の指定。imshowはRGB, contourfは塗りつぶしあり等高線, contourは塗りつぶしなし等高線
          -imshow_kws:dict, default=None
            matplotlib.pyplot.imshowに渡す引数(proba_type='imshow'のときのみに使用可能)

  2. 決定木(Decision Trees)
      木構造を使って分類する。決定木の最上層のノードを根ノード, 最下層のノードを葉ノードという。また、あるノードから見て, その上のノードが親ノード, その下のノードが子ノードである。
      model: sklearn.tree.DecisionTreeClassifier()
      parameters:
        -criterion:{“gini”, “entropy”, “log_loss”}, default=”gini”
          データ分割の評価基準
        -splitter:{“best”, “random”}, default=”best”
          各ノードでの分割方法
        -max_depth:int, default=None
          最大深度
        -min_samples_split:int or float, default=2
          ノードを分割するための最小限サンプルサイズ。整数の場合はその数自体、少数の場合は全サンプルサイズに対する割合で指定する
        -min_samples_leaf:int or float, default=1
          葉を構成するための最小限サンプル数。整数の場合はその数自体、少数の場合は全サンプルサイズに対する割合で指定する
        -min_weight_fraction_leaf:float, default=0.0
          葉ノードに必要な重みの総和
        -max_features:int, float or {“sqrt”, “log2”}, default=None
        -random_state:int, RandomState instance or None, default=None
        -max_leaf_nodes:int, default=None
        -min_impurity_decrease:float, default=0.0
        -class_weight:dict, list of dict or “balanced”, default=None
        -ccp_alpha:non-negative float, default=0.0
        -monotonic_cst:array-like of int of shape (n_features), default=None
        
            
Check


Action


参考文献
[1] Qiita: Pythonでデータの挙動を見やすくする可視化ツールを作成してみた（分類編）, https://qiita.com/c60evaporator/items/43866a42e09daebb5cc0, 2024/05/02
[2] mlxtend: plot_decision_regions: Visualize the decision regions of a classifier, https://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/, 2024/05/02
[3] 

